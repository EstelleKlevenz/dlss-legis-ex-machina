{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c1f1e0cb",
      "metadata": {
        "id": "c1f1e0cb"
      },
      "source": [
        "# Fine-tuning Classifier LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "605d0b0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "605d0b0a",
        "outputId": "0ea3b554-eb04-40af-db96-3855180c182c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# setup - load packages\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    balanced_accuracy_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Set up device (is available use GPU to speed up computations)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "seed = 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9124e7b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples party: 25281\n",
            "Test samples party: 5418\n",
            "Validation samples party: 5418\n"
          ]
        }
      ],
      "source": [
        "classifier_data = pd.read_csv(\"../data/classifier_data_A.csv\")\n",
        "# converting to huggingface dataset format\n",
        "data = Dataset.from_pandas(classifier_data)\n",
        "# splitting into train, test and validation sets\n",
        "# party data\n",
        "raw_dataset = data.shuffle(seed=seed)\n",
        "\n",
        "# 70% train, 15% test, 15% validation data\n",
        "split = raw_dataset.train_test_split(test_size=0.3, seed=seed)\n",
        "train_data = split[\"train\"]\n",
        "text_and_val_data = split[\"test\"]\n",
        "split = text_and_val_data.train_test_split(test_size=0.5, seed=seed)\n",
        "test_data = split[\"train\"]\n",
        "val_data = split[\"test\"]\n",
        "\n",
        "print(f\"Training samples party: {len(train_data)}\")\n",
        "print(f\"Test samples party: {len(test_data)}\")\n",
        "print(f\"Validation samples party: {len(val_data)}\")\n",
        "\n",
        "\n",
        "\n",
        "# data balancing??\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "39264e18",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "from typing import Union\n",
        "from typing import Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e176c9d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "WINDOW_LENGTH = 512\n",
        "STRIDE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fd8bc2b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd8bc2b5",
        "outputId": "55ab4fb4-4e66-4b0a-ed3a-4258ba8ef30f"
      },
      "outputs": [],
      "source": [
        "# Load Tokenizer\n",
        "model_name = \"bert-base-german-cased\"\n",
        "num_labels = 6\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    model_max_length=WINDOW_LENGTH\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "58a3ea65",
      "metadata": {},
      "outputs": [],
      "source": [
        "label_names = ['CDU/CSU', 'SPD', 'GRÜNE', 'FDP', 'AfD', 'LINKE']\n",
        "label2id = {label: i for i, label in enumerate(sorted(label_names))}\n",
        "id2label = {i: label for label, i in label2id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9f3ed929",
      "metadata": {},
      "outputs": [],
      "source": [
        "def sliding_window_tokenize(batch: Mapping[str, list]):\n",
        "    texts = batch[\"speech_text\"]\n",
        "    labels = batch[\"label\"]\n",
        "    \n",
        "    tokenized = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=WINDOW_LENGTH,\n",
        "        stride=STRIDE,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=False\n",
        "    )\n",
        "    tokenized[\"labels\"] = [labels[i] for i in tokenized[\"overflow_to_sample_mapping\"]]\n",
        "    return tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "15808c33",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2000/2000 [00:01<00:00, 1110.56 examples/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Beispiel: Kürzung auf 2000 Beispiele\n",
        "small_dataset = data.select(range(2000))\n",
        "tokenized_dataset = small_dataset.map(\n",
        "    sliding_window_tokenize,\n",
        "    batched=True,\n",
        "    remove_columns=small_dataset.column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "943e95d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from evaluate) (2.2.5)\n",
            "Requirement already satisfied: dill in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from evaluate) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from evaluate) (0.33.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
            "Requirement already satisfied: colorama in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\estelle\\miniconda3\\envs\\deeplearn\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c5bfef97",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "C:\\Users\\Estelle\\AppData\\Local\\Temp\\ipykernel_19236\\667101789.py:38: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:767\u001b[39m, in \u001b[36mBatchEncoding.convert_to_tensors\u001b[39m\u001b[34m(self, tensor_type, prepend_batch_axis)\u001b[39m\n\u001b[32m    766\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[32m--> \u001b[39m\u001b[32m767\u001b[39m     tensor = \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[32m    770\u001b[39m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[32m    771\u001b[39m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[32m    772\u001b[39m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[32m    773\u001b[39m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[32m    774\u001b[39m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:729\u001b[39m, in \u001b[36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[39m\u001b[34m(value, dtype)\u001b[39m\n\u001b[32m    728\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.from_numpy(np.array(value))\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mValueError\u001b[39m: too many dimensions 'str'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     25\u001b[39m training_args = TrainingArguments(\n\u001b[32m     26\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./results\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     eval_strategy=\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     fp16=torch.cuda.is_available(),\n\u001b[32m     36\u001b[39m )\n\u001b[32m     38\u001b[39m trainer = Trainer(\n\u001b[32m     39\u001b[39m     model=model,\n\u001b[32m     40\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     compute_metrics=compute_metrics,\n\u001b[32m     46\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\transformers\\trainer.py:2206\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2204\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2207\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\transformers\\trainer.py:2502\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2500\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2501\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2502\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2503\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[32m   2504\u001b[39m     step += \u001b[32m1\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\transformers\\trainer.py:5300\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5298\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5299\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5300\u001b[39m         batch_samples.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   5301\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5302\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\accelerate\\data_loader.py:567\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    565\u001b[39m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m     current_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\transformers\\data\\data_collator.py:272\u001b[39m, in \u001b[36mDataCollatorWithPadding.__call__\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     batch = \u001b[43mpad_without_fast_tokenizer_warning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[32m    281\u001b[39m         batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] = batch[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\transformers\\data\\data_collator.py:67\u001b[39m, in \u001b[36mpad_without_fast_tokenizer_warning\u001b[39m\u001b[34m(tokenizer, *pad_args, **pad_kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m tokenizer.deprecation_warnings[\u001b[33m\"\u001b[39m\u001b[33mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     padded = \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpad_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpad_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Restore the state of the warning.\u001b[39;00m\n\u001b[32m     70\u001b[39m     tokenizer.deprecation_warnings[\u001b[33m\"\u001b[39m\u001b[33mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[33m\"\u001b[39m] = warning_state\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3374\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.pad\u001b[39m\u001b[34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[39m\n\u001b[32m   3371\u001b[39m             batch_outputs[key] = []\n\u001b[32m   3372\u001b[39m         batch_outputs[key].append(value)\n\u001b[32m-> \u001b[39m\u001b[32m3374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:240\u001b[39m, in \u001b[36mBatchEncoding.__init__\u001b[39m\u001b[34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[39m\n\u001b[32m    236\u001b[39m     n_sequences = encoding[\u001b[32m0\u001b[39m].n_sequences\n\u001b[32m    238\u001b[39m \u001b[38;5;28mself\u001b[39m._n_sequences = n_sequences\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estelle\\miniconda3\\envs\\DeepLearn\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:783\u001b[39m, in \u001b[36mBatchEncoding.convert_to_tensors\u001b[39m\u001b[34m(self, tensor_type, prepend_batch_axis)\u001b[39m\n\u001b[32m    778\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33moverflowing_tokens\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    779\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    780\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    781\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    782\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m783\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    784\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    785\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpadding=True\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtruncation=True\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    786\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    787\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m expected).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    788\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-german-cased\",\n",
        "    num_labels=len(label_names),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1\": f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset.train_test_split(test_size=0.1)[\"train\"],\n",
        "    eval_dataset=tokenized_dataset.train_test_split(test_size=0.1)[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42bade2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(\"./bert_german_speech_classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ea023b1",
      "metadata": {},
      "source": [
        "# ____\n",
        "# Ella"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794e5296",
      "metadata": {
        "id": "794e5296"
      },
      "outputs": [],
      "source": [
        "def predicting_probs(model, speech):\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    #  Tokenize input speeches\n",
        "    tokens = tokenizer(speech, return_tensors=\"pt\", truncation=False)[\"input_ids\"][0]\n",
        "\n",
        "    chunks = [tokens[i:i+max_length] for i in range(0, len(tokens), max_length)]\n",
        "\n",
        "    all_probs = []\n",
        "    i = 0\n",
        "    for chunk in chunks:\n",
        "        input_dict = {\"input_ids\": chunk.unsqueeze(0)}  # Add batch dimension\n",
        "        # Add attention mask\n",
        "        input_dict[\"attention_mask\"] = (chunk != tokenizer.pad_token_id).unsqueeze(0)\n",
        "\n",
        "\n",
        "        # Run model to predict baseline\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**input_dict)\n",
        "            logits = outputs.logits\n",
        "            probabilities = F.softmax(logits, dim=1)\n",
        "            all_probs.append(probabilities)\n",
        "            i+=1\n",
        "    # averaging probabilites over all probabilities in speech parts\n",
        "    avg_probs = torch.mean(torch.cat(all_probs, dim=0), dim=0)\n",
        "    print(i , avg_probs)\n",
        "\n",
        "    return avg_probs\n",
        "\n",
        "\n",
        "def predicting_probs_to_preds(model, speech):\n",
        "    # get probabilites\n",
        "    probabilities = predicting_probs(model, speech)\n",
        "    # convert to predictions\n",
        "    predictions_nr = torch.argmax(probabilities).item()\n",
        "    predictions = label_names[predictions_nr]\n",
        "    return predictions, probabilities\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd13f334",
      "metadata": {
        "id": "bd13f334"
      },
      "outputs": [],
      "source": [
        "# collect evaluation data\n",
        "def evaluate_model(model, data):\n",
        "    prediction_list = []\n",
        "    probability_list = []\n",
        "    true_label_list = []\n",
        "\n",
        "    for i, row in enumerate(data):\n",
        "        speech = row[\"speech_text\"]\n",
        "        pred, probs = predicting_probs_to_preds(model, speech)\n",
        "        true_label = row[\"label\"]\n",
        "        prediction_list.append(pred)\n",
        "        probability_list.append(probs)\n",
        "        true_label_list.append(true_label)\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f\"Processed samples {i+1} of {len(data)} samples.\")\n",
        "\n",
        "    return prediction_list, probability_list, true_label_list\n",
        "\n",
        "\n",
        "# define function to display eval metrics\n",
        "def get_metrics(true_labels, preds):\n",
        "    metrics_summary = {}\n",
        "\n",
        "    acc = accuracy_score(true_labels, preds)\n",
        "    bal_acc = balanced_accuracy_score(true_labels, preds)\n",
        "\n",
        "    precision = precision_score(true_labels, preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(true_labels, preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(true_labels, preds, average='macro', zero_division=0)\n",
        "\n",
        "    label_order = sorted(set(true_labels).union(set(preds)))\n",
        "    report = classification_report(true_labels, preds, labels=label_order, zero_division=0)\n",
        "    metrics_summary[model_name] = {\n",
        "        'acc': acc,\n",
        "        'bal_acc': bal_acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "    # print metrics\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"  Accuracy: {acc}\")\n",
        "    print(f\"  Balanced Accuracy: {bal_acc}\")\n",
        "    print(f\"  Precision: {precision}\")\n",
        "    print(f\"  Recall: {recall}\")\n",
        "    print(f\"  F1-score: {f1}\")\n",
        "    print(f\"  Classification Report:\\n{report}\")\n",
        "\n",
        "\n",
        "    # Confusion Matrix\n",
        "    label_order = sorted(set(true_labels).union(set(preds)))\n",
        "    cm = confusion_matrix(true_labels, preds, labels=label_order)\n",
        "    cm_df = pd.DataFrame(cm, index=label_order, columns=label_order)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    return metrics_summary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ef73a1",
      "metadata": {
        "id": "76ef73a1",
        "outputId": "354d72ef-886a-4c49-e075-bea7b70fae9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 tensor([0.1638, 0.1763, 0.1356, 0.1829, 0.1976, 0.1439])\n",
            "2 tensor([0.1672, 0.1794, 0.1407, 0.1917, 0.1851, 0.1359])\n",
            "4 tensor([0.1416, 0.1736, 0.1349, 0.1676, 0.2092, 0.1731])\n",
            "1 tensor([0.1766, 0.1864, 0.1316, 0.1716, 0.1737, 0.1600])\n",
            "2 tensor([0.1714, 0.1774, 0.1366, 0.1686, 0.1937, 0.1523])\n",
            "3 tensor([0.1592, 0.1944, 0.1489, 0.1750, 0.1919, 0.1307])\n",
            "2 tensor([0.1515, 0.1829, 0.1564, 0.1505, 0.2032, 0.1556])\n",
            "2 tensor([0.1481, 0.1805, 0.1386, 0.1783, 0.2015, 0.1530])\n",
            "2 tensor([0.1567, 0.1791, 0.1503, 0.1910, 0.1812, 0.1417])\n",
            "2 tensor([0.1830, 0.1787, 0.1432, 0.1813, 0.1825, 0.1314])\n",
            "2 tensor([0.1488, 0.1712, 0.1350, 0.1757, 0.2253, 0.1440])\n",
            "1 tensor([0.1555, 0.1856, 0.1391, 0.1738, 0.2094, 0.1366])\n",
            "3 tensor([0.1610, 0.1727, 0.1535, 0.1758, 0.1915, 0.1454])\n",
            "2 tensor([0.1663, 0.1954, 0.1321, 0.1807, 0.1814, 0.1442])\n",
            "2 tensor([0.1624, 0.1677, 0.1351, 0.1836, 0.2178, 0.1335])\n",
            "3 tensor([0.1588, 0.1871, 0.1419, 0.1819, 0.1936, 0.1367])\n",
            "2 tensor([0.1479, 0.1596, 0.1451, 0.1900, 0.2028, 0.1545])\n",
            "2 tensor([0.1501, 0.1819, 0.1434, 0.1694, 0.1910, 0.1641])\n",
            "3 tensor([0.1663, 0.1714, 0.1433, 0.1874, 0.1898, 0.1418])\n",
            "3 tensor([0.1525, 0.1745, 0.1439, 0.1830, 0.1939, 0.1522])\n",
            "[tensor([0.1638, 0.1763, 0.1356, 0.1829, 0.1976, 0.1439]), tensor([0.1672, 0.1794, 0.1407, 0.1917, 0.1851, 0.1359]), tensor([0.1416, 0.1736, 0.1349, 0.1676, 0.2092, 0.1731]), tensor([0.1766, 0.1864, 0.1316, 0.1716, 0.1737, 0.1600]), tensor([0.1714, 0.1774, 0.1366, 0.1686, 0.1937, 0.1523]), tensor([0.1592, 0.1944, 0.1489, 0.1750, 0.1919, 0.1307]), tensor([0.1515, 0.1829, 0.1564, 0.1505, 0.2032, 0.1556]), tensor([0.1481, 0.1805, 0.1386, 0.1783, 0.2015, 0.1530]), tensor([0.1567, 0.1791, 0.1503, 0.1910, 0.1812, 0.1417]), tensor([0.1830, 0.1787, 0.1432, 0.1813, 0.1825, 0.1314]), tensor([0.1488, 0.1712, 0.1350, 0.1757, 0.2253, 0.1440]), tensor([0.1555, 0.1856, 0.1391, 0.1738, 0.2094, 0.1366]), tensor([0.1610, 0.1727, 0.1535, 0.1758, 0.1915, 0.1454]), tensor([0.1663, 0.1954, 0.1321, 0.1807, 0.1814, 0.1442]), tensor([0.1624, 0.1677, 0.1351, 0.1836, 0.2178, 0.1335]), tensor([0.1588, 0.1871, 0.1419, 0.1819, 0.1936, 0.1367]), tensor([0.1479, 0.1596, 0.1451, 0.1900, 0.2028, 0.1545]), tensor([0.1501, 0.1819, 0.1434, 0.1694, 0.1910, 0.1641]), tensor([0.1663, 0.1714, 0.1433, 0.1874, 0.1898, 0.1418]), tensor([0.1525, 0.1745, 0.1439, 0.1830, 0.1939, 0.1522])]\n",
            "Model: bert-base-german-cased\n",
            "  Accuracy: 0.1\n",
            "  Balanced Accuracy: 0.1\n",
            "  Precision: 0.02857142857142857\n",
            "  Recall: 0.1\n",
            "  F1-score: 0.044444444444444446\n",
            "  Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         AfD       0.14      0.50      0.22         4\n",
            "     CDU/CSU       0.00      0.00      0.00         4\n",
            "         FDP       0.00      0.00      0.00         2\n",
            "       GRÜNE       0.00      0.00      0.00         6\n",
            "         SPD       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.10        20\n",
            "   macro avg       0.03      0.10      0.04        20\n",
            "weighted avg       0.03      0.10      0.04        20\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'bert-base-german-cased': {'acc': 0.1,\n",
              "  'bal_acc': 0.1,\n",
              "  'precision': 0.02857142857142857,\n",
              "  'recall': 0.1,\n",
              "  'f1': 0.044444444444444446}}"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get zero-shot example performance\n",
        "prediction_list, probability_list, true_label_list = evaluate_model(model, val_data)\n",
        "print(probability_list)\n",
        "get_metrics(true_label_list, prediction_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "HrW5F9eWTam9",
      "metadata": {
        "id": "HrW5F9eWTam9"
      },
      "outputs": [],
      "source": [
        "classifier_data = classifier_data[:2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e9ce2f8b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "speech_text",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "label",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "65aa5ecd-96b4-490f-9845-4df75776d7c2",
              "rows": [
                [
                  "0",
                  "Herr Präsident! Kolleginnen und Kollegen! Die Bankenunion ist einer von drei Bausteinen, die dem Euro-System mehr Stabilität geben sollen. Wie wichtig mehr Stabilität ist, haben die Erfahrungen mit der Euro-Schuldenkrise gezeigt. Diese ist vom Deutschen Bundestag und mit einem großen Gemeinschaftsgeist in Deutschland erfolgreich bewältigt worden. Wir haben die Einlagen der Sparer gerettet, wir haben die richtigen Regulierungen getroffen und haben in fraktionsübergreifender Gemeinschaft im Deutschen Bundestag rund um die Uhr Schlimmeres verhindert. Das ist die Tatsache, meine Damen und Herren. Fazit ist: Stabilität erreicht man nur, wenn die Maßnahmen richtig und sachbezogen ausgestaltet werden. Dabei steht aus Sicht der Union ein Grundsatz ganz oben: Risiko und Haftung dürfen nicht voneinander getrennt werden. Dieses Prinzip, dieser Grundsatz muss zum Maßstab genommen werden. Das muss gerade auch für die Bankenunion gelten. Vor allem aber müssen die Risiken abgebaut werden, bevor eine Vollendung der Bankenunion tatsächlich verantwortet werden kann. Risiken, meine Damen und Herren, gibt es leider noch zuhauf. Das ist natürlich auch wahr. Da ist zum einen die anhaltend hohe Verschuldung einer ganzen Reihe von Mitgliedstaaten. Da gibt es zum anderen faule Kredite in erheblichem Umfang in den Bankenbilanzen. Das möchte ich noch einmal klar und deutlich hervorheben. Es ist klar: Der Steuerzahler und die Sparer müssen geschützt werden. Und Voraussetzung bleibt: Stabilität erreicht man nicht durch eine bloße Vergemeinschaftung von Schulden. Deshalb ist klar: Vor der Installierung einer europäischen Bankenunion müssen faule Kredite abgebaut werden. Hierzu gibt es eine Benchmark: Anteil der faulen Kredite in den USA 2 Prozent, in Deutschland 2,5 Prozent. Das ist etwas schlechter, aber es gibt auch Länder, bei denen der Anteil der faulen Kredite bei 15, 20 oder gar 50 Prozent liegt. Da muss gehandelt werden. Darauf müssen wir hinwirken. Das werden wir auch tun, indem wir in der Gemeinschaft dafür sorgen, dass das Stabilitätsbewusstsein stärker verankert wird. Dazu gehört natürlich auch, dass wir Staatsanleihen risikoadäquat behandeln; denn Staatsanleihen sind eben nicht risikofrei. Wir mussten immer wieder lernen, dass die Aufkäufe angeblich risikofreier Staatsanleihen oder deren Finanzierung schon ein Risiko bedeuten. Wir haben es für den richtigen Weg gehalten, die Finanzierung von Staatsanleihen in Zukunft mit Eigenkapital zu unterlegen. Wir haben es hier sicher mit einer komplexen Frage zu tun. Deshalb: Ehrgeizige Zeitpläne sind gut, aber Sorgfalt muss natürlich auch hier vor Schnelligkeit gehen. Meine Damen und Herren, wir müssen alles dafür tun, dass zunächst einmal bei den Banken gehandelt wird. Eine Eigenkapitalquote von 8 Prozent der Bilanzsumme als Sicherheit ist sicher ein richtiger Weg, um Stabilität in den Banken zu erreichen, um Vertrauen bei den Finanzmarktkunden zu schaffen. Das ist unabdingbar; denn die Eigentümer, Gläubiger und die nationale Einlagensicherung sind vor Ort gefragt, wenn die Banken in irgendeine Schieflage kommen, nicht eine Vergemeinschaftung. Wir sind richtig beraten, eine Bankenunion mit Augenmaß mit den großen Aufgaben der Regulierung zu verbinden. Wir werden darauf achten, dass die Sparer, die Finanzmarktkunden in Deutschland nicht in Haftung genommen werden. Die Steuerzahler dürfen nicht in Haftung genommen werden. Das ist die Voraussetzung für eine Bankenunion auf europäischer Ebene. Herzlichen Dank.",
                  "1"
                ],
                [
                  "1",
                  "Sehr geehrter Herr Präsident! Liebe Kolleginnen! Liebe Kollegen! Liebe Gäste auf der Tribüne! Ich finde es schön von der FDP, dass man der neuen Vorsitzenden des Finanzausschusses gleich die Möglichkeit gibt, eine Rede zu halten. Man hat überlegt: Wie schafft man das am besten? Man macht eine Aktuelle Stunde. – Es hätte heute viele Themen für eine Aktuelle Stunde gegeben. Man hätte beispielsweise über den Stand der Sondierungen zum Thema „Steuern und Finanzen“ reden können. Man hätte über die Boni der Deutschen Bank reden können. Man hätte über das Fehlen von Grundschullehrern und die finanziellen Auswirkungen auf die Haushalte reden können. Man hätte über die Hausdurchsuchungen des Zolls reden können. Sogar über die Sturm- und Hochwasserschäden der letzten Wochen hätten wir reden können. Wir hätten auch über die aktuelle Besetzung des Finanzausschusses reden können. Aber ich habe mir wirklich die Frage gestellt: Was ist an dem Thema der von Ihnen beantragten Aktuellen Stunde „Positionierung der Bundesregierung zu einer europäischen Bankenunion“ aktuell? Es ist deswegen nicht aktuell, weil wir eine geschäftsführende Bundesregierung haben, die alles das umsetzt, was wir in der Vergangenheit beschlossen haben. Ich habe heute bei den Nachrichtenagenturen und in Tickerberichten nachgesehen, aber ich habe nichts Aktuelles gefunden, und es kam ja auch nichts Aktuelles. Es gibt also in dieser Woche nichts richtig Aktuelles. Sie sind länger nicht hier gewesen, aber Aktuelle Stunden beinhalten in der Regel aktuelle Themen. – Nein, das ist nicht peinlich. Ich will etwas zur Bankenunion sagen. – Das hätten Sie auch beantragen können, haben Sie aber nicht. Deswegen rede ich jetzt zu Ihrem Antrag. Die EZB hat, so wie wir alle es mitbeschlossen haben, im November 2014 die Verantwortung für den Einheitlichen Europäischen Bankenaufsichtsmechanismus übernommen; das wissen wir alle. Das ist, wie gesagt, schon mehrere Jahre her. Seitdem ist sie für signifikante Banken zuständig. Das sind Banken, deren Bilanzsumme mindestens 30 Milliarden Euro oder 20 Prozent des BIP des Mitgliedstaates umfasst und die zu den drei größten Banken des jeweiligen Mitgliedstaats gehören. Nicht signifikante Banken werden weiterhin von nationalen Aufsichtsbehörden überwacht. Wir haben einen Einheitlichen Abwicklungsmechanismus. Das heißt, diese eben von mir angesprochenen Banken und große, grenzüberschreitende Banken werden jetzt auf europäischer Ebene einheitlich abgewickelt. Risiko und Haftung haben bei uns von Anfang an zusammengehört. Wir haben von Anfang an gesagt: Wir müssen das zusammen betrachten. Was haben wir für Banken vor uns, welche Risiken gehen sie ein, und wie müssen sie abgewickelt werden? – Bis zum 31. Dezember 2023 soll ein gemeinsamer Abwicklungsfonds eingerichtet werden, der mit 55 Milliarden Euro ausgestattet wird. Vorrangig werden Anteilseigner und Gläubiger herangezogen – das sogenannte Bail-in –, dann erst der Staat. Es gibt also keine Gemeinschaftshaftung der teilnehmenden Mitgliedstaaten durch den Fonds. Das war uns allen sehr wichtig. Auch in den Sondierungspapieren, über die Sie ja heute nicht reden wollten, steht das drin. Wir haben mit der CDU/CSU noch einmal aufgeschrieben, dass wir Haftung und Risiko nicht auseinanderfallen lassen wollen. Gerade laufen die Koalitionsverhandlungen zum Thema „Finanzen und Steuern“. Ich kann Ihnen nicht sagen, was dort gerade neu verhandelt wird; aber das können wir zu gegebener Zeit hier weiter diskutieren. Der geschäftsführende Finanzminister Altmaier hat Schwachstellen in der europäischen Währungsunion angesprochen. Er hat auch darauf hingewiesen – Kollegin Tillmann hat es angesprochen –, dass auf dem EU-Gipfel im Juni wichtige Entscheidungen für die Architektur der Euro-Zone gefällt werden müssen. Wir haben auch die Bedenken von Sparkassen und Volksbanken immer sehr ernst genommen. Dass sie ein eigenes Absicherungssystem haben und am liebsten überhaupt nicht in irgendeiner anderen Form in Anspruch genommen werden wollen, haben wir immer berücksichtigen wollen, und wir haben auch versucht, das nach Brüssel zu tragen. Dazu gibt es Anträge und Resolutionen; da haben wir in den letzten vier Jahren eine ganze Menge gemacht. Trotzdem brauchen wir eine Risikoabsicherung. Wir brauchen auch einen einheitlichen Mechanismus. Wir wollen alle zusammen in Europa weiter vorankommen. Dafür ist es wichtig, dass wir eine gute Zusammenarbeit im Euro-Raum haben. Sie können sicher sein: Der nächste Finanzminister oder die nächste Finanzministerin wird diese erfolgreiche Politik fortführen. Ich freue mich darauf. Freuen würde ich mich auch, wenn Sie nächstes Mal eine etwas aktuellere Thematik für Ihre Aktuelle Stunde aussuchen würden. Vielen Dank für Ihre Aufmerksamkeit.",
                  "5"
                ],
                [
                  "2",
                  "Herr Präsident! Liebe Kolleginnen und Kollegen! Sehr geehrte Frau Kollegin Stark-Watzinger, es ist keineswegs so, dass das Thema Bankenunion bisher hinter verschlossenen Türen diskutiert worden wäre. Auch ohne die FDP hat es dieser Deutsche Bundestag in der letzten Legislaturperiode geschafft, sich in zwei Beschlüssen mit der Einlagensicherung zu befassen. Ich empfehle Ihnen die Beschlüsse vom 4. November 2015 und vom 23. Februar 2016. Da haben wir intensiv darüber diskutiert und uns natürlich auch mit den Problemen der Bankenunion beschäftigt. Das werden wir auch weiterhin tun. Im Gegensatz zu Ihnen mit Ihrer sehr kritischen Rede sind wir aber fest davon überzeugt: Wir brauchen Europa, wir wollen Europa. Wir waren in Europa auch schon auf einem sehr guten Weg zur Regulierung der Finanzmarktkrise. – Wenn Sie kurz zuhören, will ich Ihnen gerne sagen, was wir schon alles an Positivem erreicht haben. Wir haben mit dem Stresstest begonnen. Über 130 Banken sind von der EZB geprüft worden. 25 Banken haben eine Kapitalunterdeckung aufgewiesen. Diese 25 Banken haben Kapital herangeschafft, sodass es zu einer Risikominderung gekommen ist. Wir haben eine europäische Aufsicht. Diese Aufsicht funktioniert immer besser und so gut, dass wir darüber nachdenken, ob man über eine Small Banking Box diese Regulierung bei kleineren Banken erleichtern könnte. Den Bankenabwicklungsmechanismus haben Sie beschrieben. Wir haben die Regelung, dass Steuerzahler in Europa nur noch in Ausnahmefällen für Abwicklungsbanken bezahlen müssen. Das haben wir über einen Mechanismus sichergestellt, den Bail-in, wonach Eigentümer und Anteilseigner vorrangig haften. Wir haben einen Abwicklungsfonds mit bis zu 55 Milliarden Euro installiert, der schon zu einem Drittel angespart wurde. Auch da haben wir Sicherheit in die Finanzmärkte gebracht. Wir haben die Einleger über eine Einlagensicherung geschützt. Alle Banken Europas müssen einem nationalen Einlagensicherungssystem angehören. Das ist ein Riesenschritt in die richtige Richtung. Einlegern können bis zu 100 000 Euro grenzüberschreitend ausgezahlt werden, in Sondersituationen sogar bis 500 000 Euro. Das ist ein guter Schritt in Europa. Ich finde, es gehört zu einer ehrlichen Debatte, zu sagen, dass wir massive Fortschritte für Einleger erreicht haben. Natürlich weiß ich, dass es noch eine Menge zu tun gibt. Sie haben zu Recht darauf hingewiesen, dass der Ecofin-Rat am 17. Juni 2016 genau das gesagt hat. Wir haben die ersten Schritte gemacht; ihnen müssen weitere folgen. Der wichtigste nächste Schritt ist die Risikoreduzierung, der Abbau notleidender Kredite. Eine Quote von durchschnittlich 4,6 Prozent an Non-Performing Loans in Europa ist zu viel; einige Staaten weisen sogar eine Quote von 46 Prozent auf. Wir brauchen europäische Benchmarks, mit denen die durchschnittliche Quote der Non-Performing Loans in Europa reduziert wird. Wir müssen auch das Insolvenzrecht harmonisieren. Wir brauchen europäische Vorgaben, wie bei faulen Krediten in Sicherheiten vollstreckt werden kann. In manchen Staaten geht das recht zügig; andere Staaten brauchen Jahre, bis in die Sicherheiten vollstreckt werden kann. Wir merken, dass der Bail-in-Puffer in Europa schon wieder infrage gestellt wird. Wir werden aber darauf bestehen; darin sind wir uns mit unserem ehemaligen Finanzminister Schäuble und unserem jetzigen Finanzminister Altmaier einig. Unser Staatssekretär kämpft auf allen Ebenen in Europa dafür, dass die von uns eingeführte Grenze nicht wieder infrage gestellt wird. Ich erwähne die latenten Steuern; das haben Sie noch gar nicht genannt. Natürlich dürfen Nationalstaaten über die Behandlung von latenten Steuern nicht weitere Risiken in die Bankbilanzen schieben. Bei Staatsanleihen geht es um dasselbe Thema. Wir müssen uns über die Risikogewichtung von Staatsanleihen unterhalten und dabei aber auch im Blick behalten, dass die Staaten, die dank des Rettungsschirms wieder gut dastehen, nicht zusätzliche Probleme bekommen. Ich teile Ihre Auffassung, dass es noch viel zu tun gibt. Ich teile nicht Ihre Auffassung, dass wir uns bisher nicht erfolgreich auf den Weg gemacht haben. Ich glaube, es macht keinen Sinn, alles schlechtzureden und die schlechten Seiten in den Vordergrund zu stellen. Es macht vielmehr Sinn, unserem künftigen Finanzminister gemeinsam mit auf den Weg zu geben, was wir wollen. Wir wollen zuerst eine Risikoreduktion, danach kann der zweite Schritt erfolgen. Das werden wir schaffen, das werden wir tun, und zwar öffentlich, wie immer in diesem Haus. Vielleicht gucken Sie einmal in die Anträge. Wir sollten sie dem neuen Finanzminister für seine Diskussionen auf europäischer Ebene mit auf den Weg geben. Aber ich bleibe dabei: Europa ist wichtig für Deutschland. Wir wollen eine europäische Harmonisierung. Dafür kämpfen wir mit aller Macht. Danke schön.",
                  "1"
                ],
                [
                  "3",
                  "Herr Präsident! Liebe Kolleginnen und Kollegen! Ich will jetzt gar nicht auf das eingehen, was Sie, Kollege Weyel, gesagt haben. Ich glaube, es war deutlich, dass sich selbst große Teile Ihrer eigenen Fraktion für das geschämt haben, was Sie hier dargeboten haben. Ich würde auch sagen, Frau Arndt-Brauer: Es ist durchaus ein aktuelles Thema, das man diskutieren kann. Es ist zwar der Vorwurf falsch, dass wir nicht darüber geredet haben – so wird ja gesagt, bloß weil die FDP nicht dabei war –, aber es ist in der Tat ein Thema, das in Europa auf der Tagesordnung ist und womit sich der Deutsche Bundestag beschäftigen sollte. Was in dieser Debatte problematisch ist, ist der Eindruck, den Sie, Frau Stark-Watzinger, in Ihrer Rede erweckt haben, dass nämlich diese faulen Kredite in Höhe von 950 Milliarden Euro in Europa jetzt vergemeinschaftet werden sollen. Darum geht es nicht. Niemand will das. Sie deuten das an, um die Leute vor Angst auf die Palme zu treiben. Dabei geht es doch darum, die Risiken zu reduzieren und Europa stabil zu machen. Das sollte man nicht in so eine Ecke stellen. Sie landen nämlich sonst da, wo die britischen Tories gelandet sind. Inzwischen sagen die Studien aus dem Brexit-freundlichen Haus von Theresa May: Egal wie verhandelt wird, es wird ökonomisch schlechter sein für Großbritannien. – Wer in Europa nicht mitmachen will, wird schlechter dastehen. So wird es auch uns gehen, wenn wir bei dieser Frage nur Nein sagen. Das ist keine Lösung. Sie vermitteln den Eindruck, als hätten wir immer noch nationale Bankenmärkte und als hätten wir mit den Banken in anderen Ländern überhaupt nichts zu tun. Wenn es so wäre, dann könnte man sagen: Jedem sein Einlagensicherungstöpfchen! – Aber die Welt ist schon lange nicht mehr so. Es gibt einen Finanzbinnenmarkt. Da gibt es spanische Banken, die in Deutschland Business machen. Da gibt es italienische und französische Banken. Zu meinen, dass wir in Deutschland dann, wenn es woanders ein Problem mit der Einlagensicherung gibt, nicht massiv darunter zu leiden hätten, ist einfach ökonomisch völliger Humbug. Deswegen brauchen wir eine Stabilisierung in Europa. Das ist eine notwendige Ergänzung. Um was geht es? Es geht darum, dass man für den Fall, dass der Einlagensicherungstopf eines anderen Mitgliedstaates bei einer Krise nicht ausreicht, eine Lösung hat. Jetzt schlägt die Kommission einen Weg vor – bis zu einer gemeinsamen Einlagensicherung. Da muss man einfach einmal zur Kenntnis nehmen, dass die USA mit genau einer solchen Regelung ein hervorragendes Beispiel dafür haben, dass der Steuerzahler geschützt wird. Darüber, dass das dem Schutz der Steuerzahler dient und dass es nicht darum geht, ihn zur Kasse zu bitten, haben Sie kein Wort verloren. Sie sagen: Da gibt es so viele Probleme in anderen Ländern. – Ja bitte! Schauen Sie sich doch die Zahlen an! Unsere Banken waren keinen Deut besser. Man weiß nicht, wer bei der nächsten Krise von dem gemeinsamen System profitieren würde. Vielleicht wäre es Deutschland. Unsere Banken waren in der letzten Krise nicht stabiler als die anderen. Vielleicht sind sie es auch in der nächsten Krise nicht. Nicht so eine deutsche Hybris! Das hat in Europa keinen guten Klang. Wir wissen doch, wie Versicherungen funktionieren. Ich muss doch nicht mit allen Mitgliedern der Versicherung, bei der ich Kunde bin, befreundet sein. Darunter sind viele, die ganz dumme Sachen machen. Aber die Versicherung ist für mich gut, um mich vor einem Schaden zu schützen. So würde ein Rückversicherungssystem zwischen den Einlagensystemen in Europa auch und gerade unser deutsches System stabiler machen. Deswegen sollten wir uns dem nicht verweigern, sondern daran konstruktiv mitarbeiten. In diesem Zusammenhang und nur in diesem Zusammenhang werden wir es auch schaffen, das hinzubekommen, worüber wir uns scheinbar einig sind, nämlich eine wirkliche Risikoreduzierung. Da muss noch einiges gemacht werden. Das muss man jetzt gemeinsam mit den europäischen Partnern auf den Weg bringen. So muss man bei dem Punkt, dass Banken viele Staatsanleihen eines Staates in ihren Büchern haben und damit ein Klumpenrisiko tragen, etwas tun. Da gibt es gute Vorschläge, etwa für eine stärkere Eigenkapitalunterlegung zu sorgen, bestimmte Grenzen einzuziehen. Natürlich brauchen wir das. Wir brauchen auch – ich bin gespannt, ob die bankenfreundliche FDP dabei mitmacht – eine höhere Eigenkapitalquote, also in Richtung 10 Prozent. Damit wäre das System stabiler. Aber da sind Ihre Freunde in den Banken dagegen, und deswegen wollen Sie da nicht ran, obwohl das das Problem lösen würde, dass die Banken auf zu wackligen Füßen stehen. Danke.",
                  "3"
                ],
                [
                  "4",
                  "Liebe Kolleginnen und Kollegen! Es ist vorhin von der Kollegin Arndt-Brauer gesagt worden, es sei hier immer wieder über das Thema Einlagensicherung und Bankenunion debattiert worden. Das mag so sein. Aber wenn man sich in dieser Debatte einmal anhört, welche Einigkeit zwischen CDU/CSU, SPD und Grünen bei diesem Thema besteht, dann sage ich: Eine lebendige Debatte kann das nicht gewesen sein. Dass diese Debatte aktuell ist, Frau Kollegin, zeigen die Reaktionen aus der Fachwelt. Sie hat geschrieben: Dadurch sind unsere Arbeitsplätze in Gefahr. Es ist eine Gefahr für die Arbeitsplätze, insbesondere bei den Sparkassen. – Das sagt Verdi. Wenn Verdi recht hat, dann darf man Verdi auch einmal erwähnen. Recht hat sie. Der Städtetag sagt Ähnliches. Die Volksbanken sprechen von einer existenziellen Gefahr für alle Verbundsysteme. Deswegen, Kollege Schick, sind es insbesondere die kleinen Banken, die Sorgen haben, und nicht die großen, wie Sie hier insinuiert haben. Die kleinen Banken haben die größten Sorgen vor einer einheitlichen europäischen Einlagensicherung. Um eines aus unserer Sicht klarzustellen: Bankenunion ist eine gute und richtige Idee. Aber Bankenunion funktioniert auch ohne eine einheitliche Einlagensicherung auf europäischer Ebene. Man kann sie machen, aber man muss sie nicht machen. Es ist nicht so, dass es ein elementarer und unverzichtbarer Bestandteil dessen wäre. Bankenunion ist heute Bankenaufsicht unter dem Dach der EZB und eine einheitliche Abwicklung von Banken durch eine einheitliche europäische Abwicklungsbehörde. Beides kann man noch besser machen; aber beides funktioniert für sich genommen sehr gut. Das hat mit der Einlagensicherung indirekt zu tun; aber Sie können das auf die eine wie die andere Weise lösen. Deshalb können wir hier debattieren und unterschiedlicher Meinung sein; es ist jetzt jedoch kein zwangsläufiger Weg, wie manche hier den Eindruck erwecken, in einer einheitlichen Einlagensicherung vorgezeichnet. Ich will noch einmal etwas zur Einlagensicherung bei kleinen Banken sagen. Wenn eine kleine Bank pleite ist, dann kann das nationale Einlagensicherungssystem ohne Probleme einschreiten, auch in Zukunft, es kann den Fall lösen. Interessant wird es, wenn in Zukunft bei einer einheitlichen Einlagensicherung eine große Bank nach europäischen Regeln abgewickelt werden muss. Dann entschädigt nämlich das nationale Einlagensicherungssystem den einheitlichen Abwicklungsfonds; das heißt, die Gelder, die auch die kleinen Banken eingezahlt haben, gehen dann in die Abwicklung der großen, sollen die Lasten finanzieren. Ich will einmal wissen, warum das gerechtfertigt ist und wie man es rechtfertigen kann, dass die kleinen Banken für die Abwicklung der großen zahlen sollen. Dazu habe ich heute nichts gehört, wird oft übersehen, ist aber der falsche Weg, liebe Kolleginnen und Kollegen. Wenn man über die Vollendung der Bankenunion diskutiert, dann liest man in den Papieren hauptsächlich etwas zum Thema „Einlagensicherung“. Aber die wirklich wichtigen Dinge, die in der Bankenunion zu optimieren und zu verbessern sind, finden sich in den entsprechenden Planungen nirgends. Es ist eine rein auf die Einlagensicherung beschränkte Debatte. Jedenfalls lese ich in den Papieren nicht sehr viel von anderen Dingen. – Ich will Ihnen einmal einige Beispiele nennen, bevor Sie mir widersprechen, Herr Kollege Schick. Die drei italienischen Banken, Banca Monte dei Paschi di Siena, die älteste Bank der Welt, Banca Popolare di Vicenza und die Veneto Banca, sind trotz des einheitlichen Abwicklungsmechanismus erneut mit Steuergeldern gerettet worden. Warum war das so? Weil es in den entsprechenden Rechtsgrundlagen einige Schlupflöcher gibt, die prompt beim ersten, zweiten und dritten Anwendungsfall genutzt worden sind. Nun müsste man doch zuallererst diese Schlupflöcher stopfen, damit Banken abgewickelt und nicht gerettet werden. Das wäre doch das Wichtigste. Und das erwarte ich von der Bundesregierung. Wir könnten weitermachen. Wo lese ich etwas über einen Umschuldungsmechanismus für Staaten? Den brauchen wir – Stichwort: Gläubigerhaftung. Wo lese ich etwas über Eigenkapitalunterlegung bei Staatsanleihen? Das höre ich immer wieder. Wenn man über die Fortschreibung der Bankenunion spricht, Kollege Michelbach, dann wäre das ein Beitrag zur Lösung. Ich erwarte, dass Herr Altmaier mit seinem französischen Kollegen darüber spricht und nicht zuerst über die Einlagensicherung. Im Übrigen, Kollege Schick, ist es aus meiner Sicht nicht so, wie Sie es gesagt haben, dass der Binnenmarkt für Finanzdienstleistungen bereits so gut funktioniert, dass das alles grenzüberschreitend prima möglich wäre. Es muss darauf geachtet werden, dass der Binnenmarkt besser funktioniert. Ich habe viele digitale Geschäftsmodelle von Banken gesehen, die versucht haben, ein Produkt digital im Internet zu vertreiben und es in verschiedenen europäischen Ländern anzubieten. Das scheitert noch immer sehr oft. Das wären doch Aufgaben für eine Integration der Bankenmärkte in Europa und nicht zuerst die Einlagensicherung. Die einheitliche Einlagensicherung hat erhebliche Nachteile. Sie wird für die Banken hier in Deutschland teurer. Sie ist auch mit dem Risiko verbunden, dass die Absicherung schlechter wird. Bei den Verbundsystemen und bei der Institutssicherung der Volksbanken und Sparkassen ist das evident. Ich erinnere auch an die freiwillige Einlagensicherung der Privatbanken, die natürlich ebenfalls infrage steht. Das ist doch mehr als das, was gesetzlich gefordert ist. Das ist in Gefahr, wenn man alles in eine einheitliche Einlagensicherung überführt. Das heißt, die Absicherung kann auch noch schlechter werden. Da muss man erst einmal begründen, dass das wirklich ein Fortschritt ist. Ich bin davon nicht überzeugt. Deswegen halte ich es für wichtig, dass sich die Bundesregierung hier anders positioniert, als es bisher der Fall war.",
                  "2"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Herr Präsident! Kolleginnen und Kollegen! Die ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sehr geehrter Herr Präsident! Liebe Kolleginne...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Herr Präsident! Liebe Kolleginnen und Kollegen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Herr Präsident! Liebe Kolleginnen und Kollegen...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Liebe Kolleginnen und Kollegen! Es ist vorhin ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         speech_text  label\n",
              "0  Herr Präsident! Kolleginnen und Kollegen! Die ...      1\n",
              "1  Sehr geehrter Herr Präsident! Liebe Kolleginne...      5\n",
              "2  Herr Präsident! Liebe Kolleginnen und Kollegen...      1\n",
              "3  Herr Präsident! Liebe Kolleginnen und Kollegen...      3\n",
              "4  Liebe Kolleginnen und Kollegen! Es ist vorhin ...      2"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f3689de4",
      "metadata": {},
      "outputs": [],
      "source": [
        "party_to_id = {party: i for i, party in enumerate(sorted(classifier_data['label'].unique()))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3943e5b3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'AfD': 0, 'CDU/CSU': 1, 'FDP': 2, 'GRÜNE': 3, 'LINKE': 4, 'SPD': 5}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "party_to_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "556d1025",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Estelle\\AppData\\Local\\Temp\\ipykernel_27120\\3929469336.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  classifier_data['label'] = classifier_data['label'].map(party_to_id)\n"
          ]
        }
      ],
      "source": [
        "classifier_data['label'] = classifier_data['label'].map(party_to_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d99c36d6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "speech_text",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "label",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "65441ed5-9648-4d22-aebd-7f8c56cd0e8f",
              "rows": [
                [
                  "0",
                  "Herr Präsident! Kolleginnen und Kollegen! Die Bankenunion ist einer von drei Bausteinen, die dem Euro-System mehr Stabilität geben sollen. Wie wichtig mehr Stabilität ist, haben die Erfahrungen mit der Euro-Schuldenkrise gezeigt. Diese ist vom Deutschen Bundestag und mit einem großen Gemeinschaftsgeist in Deutschland erfolgreich bewältigt worden. Wir haben die Einlagen der Sparer gerettet, wir haben die richtigen Regulierungen getroffen und haben in fraktionsübergreifender Gemeinschaft im Deutschen Bundestag rund um die Uhr Schlimmeres verhindert. Das ist die Tatsache, meine Damen und Herren. Fazit ist: Stabilität erreicht man nur, wenn die Maßnahmen richtig und sachbezogen ausgestaltet werden. Dabei steht aus Sicht der Union ein Grundsatz ganz oben: Risiko und Haftung dürfen nicht voneinander getrennt werden. Dieses Prinzip, dieser Grundsatz muss zum Maßstab genommen werden. Das muss gerade auch für die Bankenunion gelten. Vor allem aber müssen die Risiken abgebaut werden, bevor eine Vollendung der Bankenunion tatsächlich verantwortet werden kann. Risiken, meine Damen und Herren, gibt es leider noch zuhauf. Das ist natürlich auch wahr. Da ist zum einen die anhaltend hohe Verschuldung einer ganzen Reihe von Mitgliedstaaten. Da gibt es zum anderen faule Kredite in erheblichem Umfang in den Bankenbilanzen. Das möchte ich noch einmal klar und deutlich hervorheben. Es ist klar: Der Steuerzahler und die Sparer müssen geschützt werden. Und Voraussetzung bleibt: Stabilität erreicht man nicht durch eine bloße Vergemeinschaftung von Schulden. Deshalb ist klar: Vor der Installierung einer europäischen Bankenunion müssen faule Kredite abgebaut werden. Hierzu gibt es eine Benchmark: Anteil der faulen Kredite in den USA 2 Prozent, in Deutschland 2,5 Prozent. Das ist etwas schlechter, aber es gibt auch Länder, bei denen der Anteil der faulen Kredite bei 15, 20 oder gar 50 Prozent liegt. Da muss gehandelt werden. Darauf müssen wir hinwirken. Das werden wir auch tun, indem wir in der Gemeinschaft dafür sorgen, dass das Stabilitätsbewusstsein stärker verankert wird. Dazu gehört natürlich auch, dass wir Staatsanleihen risikoadäquat behandeln; denn Staatsanleihen sind eben nicht risikofrei. Wir mussten immer wieder lernen, dass die Aufkäufe angeblich risikofreier Staatsanleihen oder deren Finanzierung schon ein Risiko bedeuten. Wir haben es für den richtigen Weg gehalten, die Finanzierung von Staatsanleihen in Zukunft mit Eigenkapital zu unterlegen. Wir haben es hier sicher mit einer komplexen Frage zu tun. Deshalb: Ehrgeizige Zeitpläne sind gut, aber Sorgfalt muss natürlich auch hier vor Schnelligkeit gehen. Meine Damen und Herren, wir müssen alles dafür tun, dass zunächst einmal bei den Banken gehandelt wird. Eine Eigenkapitalquote von 8 Prozent der Bilanzsumme als Sicherheit ist sicher ein richtiger Weg, um Stabilität in den Banken zu erreichen, um Vertrauen bei den Finanzmarktkunden zu schaffen. Das ist unabdingbar; denn die Eigentümer, Gläubiger und die nationale Einlagensicherung sind vor Ort gefragt, wenn die Banken in irgendeine Schieflage kommen, nicht eine Vergemeinschaftung. Wir sind richtig beraten, eine Bankenunion mit Augenmaß mit den großen Aufgaben der Regulierung zu verbinden. Wir werden darauf achten, dass die Sparer, die Finanzmarktkunden in Deutschland nicht in Haftung genommen werden. Die Steuerzahler dürfen nicht in Haftung genommen werden. Das ist die Voraussetzung für eine Bankenunion auf europäischer Ebene. Herzlichen Dank.",
                  "1"
                ],
                [
                  "1",
                  "Sehr geehrter Herr Präsident! Liebe Kolleginnen! Liebe Kollegen! Liebe Gäste auf der Tribüne! Ich finde es schön von der FDP, dass man der neuen Vorsitzenden des Finanzausschusses gleich die Möglichkeit gibt, eine Rede zu halten. Man hat überlegt: Wie schafft man das am besten? Man macht eine Aktuelle Stunde. – Es hätte heute viele Themen für eine Aktuelle Stunde gegeben. Man hätte beispielsweise über den Stand der Sondierungen zum Thema „Steuern und Finanzen“ reden können. Man hätte über die Boni der Deutschen Bank reden können. Man hätte über das Fehlen von Grundschullehrern und die finanziellen Auswirkungen auf die Haushalte reden können. Man hätte über die Hausdurchsuchungen des Zolls reden können. Sogar über die Sturm- und Hochwasserschäden der letzten Wochen hätten wir reden können. Wir hätten auch über die aktuelle Besetzung des Finanzausschusses reden können. Aber ich habe mir wirklich die Frage gestellt: Was ist an dem Thema der von Ihnen beantragten Aktuellen Stunde „Positionierung der Bundesregierung zu einer europäischen Bankenunion“ aktuell? Es ist deswegen nicht aktuell, weil wir eine geschäftsführende Bundesregierung haben, die alles das umsetzt, was wir in der Vergangenheit beschlossen haben. Ich habe heute bei den Nachrichtenagenturen und in Tickerberichten nachgesehen, aber ich habe nichts Aktuelles gefunden, und es kam ja auch nichts Aktuelles. Es gibt also in dieser Woche nichts richtig Aktuelles. Sie sind länger nicht hier gewesen, aber Aktuelle Stunden beinhalten in der Regel aktuelle Themen. – Nein, das ist nicht peinlich. Ich will etwas zur Bankenunion sagen. – Das hätten Sie auch beantragen können, haben Sie aber nicht. Deswegen rede ich jetzt zu Ihrem Antrag. Die EZB hat, so wie wir alle es mitbeschlossen haben, im November 2014 die Verantwortung für den Einheitlichen Europäischen Bankenaufsichtsmechanismus übernommen; das wissen wir alle. Das ist, wie gesagt, schon mehrere Jahre her. Seitdem ist sie für signifikante Banken zuständig. Das sind Banken, deren Bilanzsumme mindestens 30 Milliarden Euro oder 20 Prozent des BIP des Mitgliedstaates umfasst und die zu den drei größten Banken des jeweiligen Mitgliedstaats gehören. Nicht signifikante Banken werden weiterhin von nationalen Aufsichtsbehörden überwacht. Wir haben einen Einheitlichen Abwicklungsmechanismus. Das heißt, diese eben von mir angesprochenen Banken und große, grenzüberschreitende Banken werden jetzt auf europäischer Ebene einheitlich abgewickelt. Risiko und Haftung haben bei uns von Anfang an zusammengehört. Wir haben von Anfang an gesagt: Wir müssen das zusammen betrachten. Was haben wir für Banken vor uns, welche Risiken gehen sie ein, und wie müssen sie abgewickelt werden? – Bis zum 31. Dezember 2023 soll ein gemeinsamer Abwicklungsfonds eingerichtet werden, der mit 55 Milliarden Euro ausgestattet wird. Vorrangig werden Anteilseigner und Gläubiger herangezogen – das sogenannte Bail-in –, dann erst der Staat. Es gibt also keine Gemeinschaftshaftung der teilnehmenden Mitgliedstaaten durch den Fonds. Das war uns allen sehr wichtig. Auch in den Sondierungspapieren, über die Sie ja heute nicht reden wollten, steht das drin. Wir haben mit der CDU/CSU noch einmal aufgeschrieben, dass wir Haftung und Risiko nicht auseinanderfallen lassen wollen. Gerade laufen die Koalitionsverhandlungen zum Thema „Finanzen und Steuern“. Ich kann Ihnen nicht sagen, was dort gerade neu verhandelt wird; aber das können wir zu gegebener Zeit hier weiter diskutieren. Der geschäftsführende Finanzminister Altmaier hat Schwachstellen in der europäischen Währungsunion angesprochen. Er hat auch darauf hingewiesen – Kollegin Tillmann hat es angesprochen –, dass auf dem EU-Gipfel im Juni wichtige Entscheidungen für die Architektur der Euro-Zone gefällt werden müssen. Wir haben auch die Bedenken von Sparkassen und Volksbanken immer sehr ernst genommen. Dass sie ein eigenes Absicherungssystem haben und am liebsten überhaupt nicht in irgendeiner anderen Form in Anspruch genommen werden wollen, haben wir immer berücksichtigen wollen, und wir haben auch versucht, das nach Brüssel zu tragen. Dazu gibt es Anträge und Resolutionen; da haben wir in den letzten vier Jahren eine ganze Menge gemacht. Trotzdem brauchen wir eine Risikoabsicherung. Wir brauchen auch einen einheitlichen Mechanismus. Wir wollen alle zusammen in Europa weiter vorankommen. Dafür ist es wichtig, dass wir eine gute Zusammenarbeit im Euro-Raum haben. Sie können sicher sein: Der nächste Finanzminister oder die nächste Finanzministerin wird diese erfolgreiche Politik fortführen. Ich freue mich darauf. Freuen würde ich mich auch, wenn Sie nächstes Mal eine etwas aktuellere Thematik für Ihre Aktuelle Stunde aussuchen würden. Vielen Dank für Ihre Aufmerksamkeit.",
                  "5"
                ],
                [
                  "2",
                  "Herr Präsident! Liebe Kolleginnen und Kollegen! Sehr geehrte Frau Kollegin Stark-Watzinger, es ist keineswegs so, dass das Thema Bankenunion bisher hinter verschlossenen Türen diskutiert worden wäre. Auch ohne die FDP hat es dieser Deutsche Bundestag in der letzten Legislaturperiode geschafft, sich in zwei Beschlüssen mit der Einlagensicherung zu befassen. Ich empfehle Ihnen die Beschlüsse vom 4. November 2015 und vom 23. Februar 2016. Da haben wir intensiv darüber diskutiert und uns natürlich auch mit den Problemen der Bankenunion beschäftigt. Das werden wir auch weiterhin tun. Im Gegensatz zu Ihnen mit Ihrer sehr kritischen Rede sind wir aber fest davon überzeugt: Wir brauchen Europa, wir wollen Europa. Wir waren in Europa auch schon auf einem sehr guten Weg zur Regulierung der Finanzmarktkrise. – Wenn Sie kurz zuhören, will ich Ihnen gerne sagen, was wir schon alles an Positivem erreicht haben. Wir haben mit dem Stresstest begonnen. Über 130 Banken sind von der EZB geprüft worden. 25 Banken haben eine Kapitalunterdeckung aufgewiesen. Diese 25 Banken haben Kapital herangeschafft, sodass es zu einer Risikominderung gekommen ist. Wir haben eine europäische Aufsicht. Diese Aufsicht funktioniert immer besser und so gut, dass wir darüber nachdenken, ob man über eine Small Banking Box diese Regulierung bei kleineren Banken erleichtern könnte. Den Bankenabwicklungsmechanismus haben Sie beschrieben. Wir haben die Regelung, dass Steuerzahler in Europa nur noch in Ausnahmefällen für Abwicklungsbanken bezahlen müssen. Das haben wir über einen Mechanismus sichergestellt, den Bail-in, wonach Eigentümer und Anteilseigner vorrangig haften. Wir haben einen Abwicklungsfonds mit bis zu 55 Milliarden Euro installiert, der schon zu einem Drittel angespart wurde. Auch da haben wir Sicherheit in die Finanzmärkte gebracht. Wir haben die Einleger über eine Einlagensicherung geschützt. Alle Banken Europas müssen einem nationalen Einlagensicherungssystem angehören. Das ist ein Riesenschritt in die richtige Richtung. Einlegern können bis zu 100 000 Euro grenzüberschreitend ausgezahlt werden, in Sondersituationen sogar bis 500 000 Euro. Das ist ein guter Schritt in Europa. Ich finde, es gehört zu einer ehrlichen Debatte, zu sagen, dass wir massive Fortschritte für Einleger erreicht haben. Natürlich weiß ich, dass es noch eine Menge zu tun gibt. Sie haben zu Recht darauf hingewiesen, dass der Ecofin-Rat am 17. Juni 2016 genau das gesagt hat. Wir haben die ersten Schritte gemacht; ihnen müssen weitere folgen. Der wichtigste nächste Schritt ist die Risikoreduzierung, der Abbau notleidender Kredite. Eine Quote von durchschnittlich 4,6 Prozent an Non-Performing Loans in Europa ist zu viel; einige Staaten weisen sogar eine Quote von 46 Prozent auf. Wir brauchen europäische Benchmarks, mit denen die durchschnittliche Quote der Non-Performing Loans in Europa reduziert wird. Wir müssen auch das Insolvenzrecht harmonisieren. Wir brauchen europäische Vorgaben, wie bei faulen Krediten in Sicherheiten vollstreckt werden kann. In manchen Staaten geht das recht zügig; andere Staaten brauchen Jahre, bis in die Sicherheiten vollstreckt werden kann. Wir merken, dass der Bail-in-Puffer in Europa schon wieder infrage gestellt wird. Wir werden aber darauf bestehen; darin sind wir uns mit unserem ehemaligen Finanzminister Schäuble und unserem jetzigen Finanzminister Altmaier einig. Unser Staatssekretär kämpft auf allen Ebenen in Europa dafür, dass die von uns eingeführte Grenze nicht wieder infrage gestellt wird. Ich erwähne die latenten Steuern; das haben Sie noch gar nicht genannt. Natürlich dürfen Nationalstaaten über die Behandlung von latenten Steuern nicht weitere Risiken in die Bankbilanzen schieben. Bei Staatsanleihen geht es um dasselbe Thema. Wir müssen uns über die Risikogewichtung von Staatsanleihen unterhalten und dabei aber auch im Blick behalten, dass die Staaten, die dank des Rettungsschirms wieder gut dastehen, nicht zusätzliche Probleme bekommen. Ich teile Ihre Auffassung, dass es noch viel zu tun gibt. Ich teile nicht Ihre Auffassung, dass wir uns bisher nicht erfolgreich auf den Weg gemacht haben. Ich glaube, es macht keinen Sinn, alles schlechtzureden und die schlechten Seiten in den Vordergrund zu stellen. Es macht vielmehr Sinn, unserem künftigen Finanzminister gemeinsam mit auf den Weg zu geben, was wir wollen. Wir wollen zuerst eine Risikoreduktion, danach kann der zweite Schritt erfolgen. Das werden wir schaffen, das werden wir tun, und zwar öffentlich, wie immer in diesem Haus. Vielleicht gucken Sie einmal in die Anträge. Wir sollten sie dem neuen Finanzminister für seine Diskussionen auf europäischer Ebene mit auf den Weg geben. Aber ich bleibe dabei: Europa ist wichtig für Deutschland. Wir wollen eine europäische Harmonisierung. Dafür kämpfen wir mit aller Macht. Danke schön.",
                  "1"
                ],
                [
                  "3",
                  "Herr Präsident! Liebe Kolleginnen und Kollegen! Ich will jetzt gar nicht auf das eingehen, was Sie, Kollege Weyel, gesagt haben. Ich glaube, es war deutlich, dass sich selbst große Teile Ihrer eigenen Fraktion für das geschämt haben, was Sie hier dargeboten haben. Ich würde auch sagen, Frau Arndt-Brauer: Es ist durchaus ein aktuelles Thema, das man diskutieren kann. Es ist zwar der Vorwurf falsch, dass wir nicht darüber geredet haben – so wird ja gesagt, bloß weil die FDP nicht dabei war –, aber es ist in der Tat ein Thema, das in Europa auf der Tagesordnung ist und womit sich der Deutsche Bundestag beschäftigen sollte. Was in dieser Debatte problematisch ist, ist der Eindruck, den Sie, Frau Stark-Watzinger, in Ihrer Rede erweckt haben, dass nämlich diese faulen Kredite in Höhe von 950 Milliarden Euro in Europa jetzt vergemeinschaftet werden sollen. Darum geht es nicht. Niemand will das. Sie deuten das an, um die Leute vor Angst auf die Palme zu treiben. Dabei geht es doch darum, die Risiken zu reduzieren und Europa stabil zu machen. Das sollte man nicht in so eine Ecke stellen. Sie landen nämlich sonst da, wo die britischen Tories gelandet sind. Inzwischen sagen die Studien aus dem Brexit-freundlichen Haus von Theresa May: Egal wie verhandelt wird, es wird ökonomisch schlechter sein für Großbritannien. – Wer in Europa nicht mitmachen will, wird schlechter dastehen. So wird es auch uns gehen, wenn wir bei dieser Frage nur Nein sagen. Das ist keine Lösung. Sie vermitteln den Eindruck, als hätten wir immer noch nationale Bankenmärkte und als hätten wir mit den Banken in anderen Ländern überhaupt nichts zu tun. Wenn es so wäre, dann könnte man sagen: Jedem sein Einlagensicherungstöpfchen! – Aber die Welt ist schon lange nicht mehr so. Es gibt einen Finanzbinnenmarkt. Da gibt es spanische Banken, die in Deutschland Business machen. Da gibt es italienische und französische Banken. Zu meinen, dass wir in Deutschland dann, wenn es woanders ein Problem mit der Einlagensicherung gibt, nicht massiv darunter zu leiden hätten, ist einfach ökonomisch völliger Humbug. Deswegen brauchen wir eine Stabilisierung in Europa. Das ist eine notwendige Ergänzung. Um was geht es? Es geht darum, dass man für den Fall, dass der Einlagensicherungstopf eines anderen Mitgliedstaates bei einer Krise nicht ausreicht, eine Lösung hat. Jetzt schlägt die Kommission einen Weg vor – bis zu einer gemeinsamen Einlagensicherung. Da muss man einfach einmal zur Kenntnis nehmen, dass die USA mit genau einer solchen Regelung ein hervorragendes Beispiel dafür haben, dass der Steuerzahler geschützt wird. Darüber, dass das dem Schutz der Steuerzahler dient und dass es nicht darum geht, ihn zur Kasse zu bitten, haben Sie kein Wort verloren. Sie sagen: Da gibt es so viele Probleme in anderen Ländern. – Ja bitte! Schauen Sie sich doch die Zahlen an! Unsere Banken waren keinen Deut besser. Man weiß nicht, wer bei der nächsten Krise von dem gemeinsamen System profitieren würde. Vielleicht wäre es Deutschland. Unsere Banken waren in der letzten Krise nicht stabiler als die anderen. Vielleicht sind sie es auch in der nächsten Krise nicht. Nicht so eine deutsche Hybris! Das hat in Europa keinen guten Klang. Wir wissen doch, wie Versicherungen funktionieren. Ich muss doch nicht mit allen Mitgliedern der Versicherung, bei der ich Kunde bin, befreundet sein. Darunter sind viele, die ganz dumme Sachen machen. Aber die Versicherung ist für mich gut, um mich vor einem Schaden zu schützen. So würde ein Rückversicherungssystem zwischen den Einlagensystemen in Europa auch und gerade unser deutsches System stabiler machen. Deswegen sollten wir uns dem nicht verweigern, sondern daran konstruktiv mitarbeiten. In diesem Zusammenhang und nur in diesem Zusammenhang werden wir es auch schaffen, das hinzubekommen, worüber wir uns scheinbar einig sind, nämlich eine wirkliche Risikoreduzierung. Da muss noch einiges gemacht werden. Das muss man jetzt gemeinsam mit den europäischen Partnern auf den Weg bringen. So muss man bei dem Punkt, dass Banken viele Staatsanleihen eines Staates in ihren Büchern haben und damit ein Klumpenrisiko tragen, etwas tun. Da gibt es gute Vorschläge, etwa für eine stärkere Eigenkapitalunterlegung zu sorgen, bestimmte Grenzen einzuziehen. Natürlich brauchen wir das. Wir brauchen auch – ich bin gespannt, ob die bankenfreundliche FDP dabei mitmacht – eine höhere Eigenkapitalquote, also in Richtung 10 Prozent. Damit wäre das System stabiler. Aber da sind Ihre Freunde in den Banken dagegen, und deswegen wollen Sie da nicht ran, obwohl das das Problem lösen würde, dass die Banken auf zu wackligen Füßen stehen. Danke.",
                  "3"
                ],
                [
                  "4",
                  "Liebe Kolleginnen und Kollegen! Es ist vorhin von der Kollegin Arndt-Brauer gesagt worden, es sei hier immer wieder über das Thema Einlagensicherung und Bankenunion debattiert worden. Das mag so sein. Aber wenn man sich in dieser Debatte einmal anhört, welche Einigkeit zwischen CDU/CSU, SPD und Grünen bei diesem Thema besteht, dann sage ich: Eine lebendige Debatte kann das nicht gewesen sein. Dass diese Debatte aktuell ist, Frau Kollegin, zeigen die Reaktionen aus der Fachwelt. Sie hat geschrieben: Dadurch sind unsere Arbeitsplätze in Gefahr. Es ist eine Gefahr für die Arbeitsplätze, insbesondere bei den Sparkassen. – Das sagt Verdi. Wenn Verdi recht hat, dann darf man Verdi auch einmal erwähnen. Recht hat sie. Der Städtetag sagt Ähnliches. Die Volksbanken sprechen von einer existenziellen Gefahr für alle Verbundsysteme. Deswegen, Kollege Schick, sind es insbesondere die kleinen Banken, die Sorgen haben, und nicht die großen, wie Sie hier insinuiert haben. Die kleinen Banken haben die größten Sorgen vor einer einheitlichen europäischen Einlagensicherung. Um eines aus unserer Sicht klarzustellen: Bankenunion ist eine gute und richtige Idee. Aber Bankenunion funktioniert auch ohne eine einheitliche Einlagensicherung auf europäischer Ebene. Man kann sie machen, aber man muss sie nicht machen. Es ist nicht so, dass es ein elementarer und unverzichtbarer Bestandteil dessen wäre. Bankenunion ist heute Bankenaufsicht unter dem Dach der EZB und eine einheitliche Abwicklung von Banken durch eine einheitliche europäische Abwicklungsbehörde. Beides kann man noch besser machen; aber beides funktioniert für sich genommen sehr gut. Das hat mit der Einlagensicherung indirekt zu tun; aber Sie können das auf die eine wie die andere Weise lösen. Deshalb können wir hier debattieren und unterschiedlicher Meinung sein; es ist jetzt jedoch kein zwangsläufiger Weg, wie manche hier den Eindruck erwecken, in einer einheitlichen Einlagensicherung vorgezeichnet. Ich will noch einmal etwas zur Einlagensicherung bei kleinen Banken sagen. Wenn eine kleine Bank pleite ist, dann kann das nationale Einlagensicherungssystem ohne Probleme einschreiten, auch in Zukunft, es kann den Fall lösen. Interessant wird es, wenn in Zukunft bei einer einheitlichen Einlagensicherung eine große Bank nach europäischen Regeln abgewickelt werden muss. Dann entschädigt nämlich das nationale Einlagensicherungssystem den einheitlichen Abwicklungsfonds; das heißt, die Gelder, die auch die kleinen Banken eingezahlt haben, gehen dann in die Abwicklung der großen, sollen die Lasten finanzieren. Ich will einmal wissen, warum das gerechtfertigt ist und wie man es rechtfertigen kann, dass die kleinen Banken für die Abwicklung der großen zahlen sollen. Dazu habe ich heute nichts gehört, wird oft übersehen, ist aber der falsche Weg, liebe Kolleginnen und Kollegen. Wenn man über die Vollendung der Bankenunion diskutiert, dann liest man in den Papieren hauptsächlich etwas zum Thema „Einlagensicherung“. Aber die wirklich wichtigen Dinge, die in der Bankenunion zu optimieren und zu verbessern sind, finden sich in den entsprechenden Planungen nirgends. Es ist eine rein auf die Einlagensicherung beschränkte Debatte. Jedenfalls lese ich in den Papieren nicht sehr viel von anderen Dingen. – Ich will Ihnen einmal einige Beispiele nennen, bevor Sie mir widersprechen, Herr Kollege Schick. Die drei italienischen Banken, Banca Monte dei Paschi di Siena, die älteste Bank der Welt, Banca Popolare di Vicenza und die Veneto Banca, sind trotz des einheitlichen Abwicklungsmechanismus erneut mit Steuergeldern gerettet worden. Warum war das so? Weil es in den entsprechenden Rechtsgrundlagen einige Schlupflöcher gibt, die prompt beim ersten, zweiten und dritten Anwendungsfall genutzt worden sind. Nun müsste man doch zuallererst diese Schlupflöcher stopfen, damit Banken abgewickelt und nicht gerettet werden. Das wäre doch das Wichtigste. Und das erwarte ich von der Bundesregierung. Wir könnten weitermachen. Wo lese ich etwas über einen Umschuldungsmechanismus für Staaten? Den brauchen wir – Stichwort: Gläubigerhaftung. Wo lese ich etwas über Eigenkapitalunterlegung bei Staatsanleihen? Das höre ich immer wieder. Wenn man über die Fortschreibung der Bankenunion spricht, Kollege Michelbach, dann wäre das ein Beitrag zur Lösung. Ich erwarte, dass Herr Altmaier mit seinem französischen Kollegen darüber spricht und nicht zuerst über die Einlagensicherung. Im Übrigen, Kollege Schick, ist es aus meiner Sicht nicht so, wie Sie es gesagt haben, dass der Binnenmarkt für Finanzdienstleistungen bereits so gut funktioniert, dass das alles grenzüberschreitend prima möglich wäre. Es muss darauf geachtet werden, dass der Binnenmarkt besser funktioniert. Ich habe viele digitale Geschäftsmodelle von Banken gesehen, die versucht haben, ein Produkt digital im Internet zu vertreiben und es in verschiedenen europäischen Ländern anzubieten. Das scheitert noch immer sehr oft. Das wären doch Aufgaben für eine Integration der Bankenmärkte in Europa und nicht zuerst die Einlagensicherung. Die einheitliche Einlagensicherung hat erhebliche Nachteile. Sie wird für die Banken hier in Deutschland teurer. Sie ist auch mit dem Risiko verbunden, dass die Absicherung schlechter wird. Bei den Verbundsystemen und bei der Institutssicherung der Volksbanken und Sparkassen ist das evident. Ich erinnere auch an die freiwillige Einlagensicherung der Privatbanken, die natürlich ebenfalls infrage steht. Das ist doch mehr als das, was gesetzlich gefordert ist. Das ist in Gefahr, wenn man alles in eine einheitliche Einlagensicherung überführt. Das heißt, die Absicherung kann auch noch schlechter werden. Da muss man erst einmal begründen, dass das wirklich ein Fortschritt ist. Ich bin davon nicht überzeugt. Deswegen halte ich es für wichtig, dass sich die Bundesregierung hier anders positioniert, als es bisher der Fall war.",
                  "2"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Herr Präsident! Kolleginnen und Kollegen! Die ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sehr geehrter Herr Präsident! Liebe Kolleginne...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Herr Präsident! Liebe Kolleginnen und Kollegen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Herr Präsident! Liebe Kolleginnen und Kollegen...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Liebe Kolleginnen und Kollegen! Es ist vorhin ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         speech_text  label\n",
              "0  Herr Präsident! Kolleginnen und Kollegen! Die ...      1\n",
              "1  Sehr geehrter Herr Präsident! Liebe Kolleginne...      5\n",
              "2  Herr Präsident! Liebe Kolleginnen und Kollegen...      1\n",
              "3  Herr Präsident! Liebe Kolleginnen und Kollegen...      3\n",
              "4  Liebe Kolleginnen und Kollegen! Es ist vorhin ...      2"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e33c6f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "82fb3c74149549548fa0978404b28325",
            "694f85eb9d41453ea6a15663cc77d904",
            "f1f30762e0ee45c5ae0546c9f28ab80e",
            "6930ad9c33554cb58eca93d56e18bafe",
            "9bebe5cafdb24289bd757def59ef2d0f",
            "10b0f660d8f84900bc9c17f84fa1a848",
            "e411ce98cfc2494ea81e0f571d87a683",
            "4244d8904a824677b0a8e813691bd8a2",
            "8e78d00a6096452b9359418790989408",
            "122df21abbff4c62b25a394694a45790",
            "3eddf7ad5a8349eea83a0f7b9cc38b08"
          ]
        },
        "id": "1e33c6f7",
        "outputId": "208c61b3-b742-4ad1-d2ab-0912b250cf97"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82fb3c74149549548fa0978404b28325",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/36117 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(classifier_data)\n",
        "\n",
        "# Tokenize\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['speech_text'], truncation=True, padding='max_length', max_length=max_length)\n",
        "\n",
        "dataset = dataset.map(tokenize, batched=True)\n",
        "dataset = dataset.rename_column(\"label\", \"labels\")  # required name\n",
        "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.3)  # 90% train, 10% val\n",
        "train_dataset = dataset['train']\n",
        "val_and_test_dataset = dataset['test']\n",
        "val_and_test_dataset = val_and_test_dataset.train_test_split(test_size=0.5)  # 90% train, 10% val\n",
        "val_dataset = val_and_test_dataset['train']\n",
        "test_dataset = val_and_test_dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a1a9a357",
      "metadata": {
        "id": "a1a9a357"
      },
      "outputs": [],
      "source": [
        "# fine-tunen\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-finetuned\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\"\n",
        ")\n",
        "\n",
        "\n",
        "import evaluate\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "47c2a569",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "47c2a569",
        "outputId": "5af1b6db-2028-48f3-b4b7-7e5e99248237"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1549188525.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9483' max='9483' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9483/9483 28:25, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.949800</td>\n",
              "      <td>0.873547</td>\n",
              "      <td>0.659468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.672300</td>\n",
              "      <td>0.771991</td>\n",
              "      <td>0.706165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.396900</td>\n",
              "      <td>0.857263</td>\n",
              "      <td>0.717977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9483, training_loss=0.7657745885884197, metrics={'train_runtime': 1706.159, 'train_samples_per_second': 44.452, 'train_steps_per_second': 5.558, 'total_flos': 1.9955848447973376e+16, 'train_loss': 0.7657745885884197, 'epoch': 3.0})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# train\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "3fd06889",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3fd06889",
        "outputId": "0dcf4e2c-301e-4669-c380-1171194f6d7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='678' max='678' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [678/678 00:35]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.8572631478309631,\n",
              " 'eval_accuracy': 0.7179771133259505,\n",
              " 'eval_runtime': 35.9672,\n",
              " 'eval_samples_per_second': 150.637,\n",
              " 'eval_steps_per_second': 18.851,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# validaten\n",
        "\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eefcb924",
      "metadata": {
        "id": "eefcb924"
      },
      "outputs": [],
      "source": [
        "# compare 2 versions (erinnern!)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "657c9d90",
      "metadata": {
        "id": "657c9d90"
      },
      "outputs": [],
      "source": [
        "# outcomes test data conf matrix, accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272215fe",
      "metadata": {
        "id": "272215fe"
      },
      "outputs": [],
      "source": [
        "# save model for futher tests on LLM generated speeches\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d23ef6",
      "metadata": {
        "id": "40d23ef6"
      },
      "source": [
        "__________________________________________________________________________________\n",
        "\n",
        "Old to save\n",
        "__________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1994e316",
      "metadata": {
        "id": "1994e316"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "model_name = \"bert-base-german-cased\"\n",
        "num_labels = 6\n",
        "max_length = 512\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels= num_labels) # classification head with one linear layer and num_label outputs is added on top of model here.\n",
        "\n",
        "print(f\"Model parameters: {model.num_parameters():,}\")\n",
        "\n",
        "# Put model in eval mode\n",
        "model.eval()\n",
        "\n",
        "# Define possible label names\n",
        "label_names = ['CDU/CSU', 'SPD', 'GRÜNE', 'FDP', 'AfD', 'LINKE']\n",
        "\n",
        "#  Tokenize input speeches\n",
        "inputs = tokenizer(val_data_subset[\"speech_text\"], return_tensors=\"pt\", padding=True, truncation=False) # padding pads all speeches to the same length and truncation cuts all speeches to 512 tokens\n",
        "\n",
        "# Run model to predict basline\n",
        "with torch.no_grad(): # turns of gradient tracking, since we are not training\n",
        "    outputs = model(**inputs) # passes tokenized inputs into model, returns output dict\n",
        "    logits = outputs.logits # output dict contains logits\n",
        "    probabilities = F.softmax(logits, dim=1) # logits to probabilities\n",
        "    predictions = torch.argmax(probabilities, dim=1) # probabilities to predictions (i.e. highest probability)\n",
        "\n",
        "# 7. Print prediction examples\n",
        "for i, pred in enumerate(predictions):\n",
        "    print(f\"Speech {i+1}: predicted party = {label_names[pred]}\")\n",
        "print(logits)\n",
        "\n",
        "for i, probs in enumerate(probabilities):\n",
        "    print(f\"Speech {i+1} prediction:\")\n",
        "    for label, prob in zip(label_names, probs):\n",
        "        print(f\"  {label:7s}: {prob.item():.2%}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DeepLearn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10b0f660d8f84900bc9c17f84fa1a848": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122df21abbff4c62b25a394694a45790": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eddf7ad5a8349eea83a0f7b9cc38b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4244d8904a824677b0a8e813691bd8a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6930ad9c33554cb58eca93d56e18bafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_122df21abbff4c62b25a394694a45790",
            "placeholder": "​",
            "style": "IPY_MODEL_3eddf7ad5a8349eea83a0f7b9cc38b08",
            "value": " 36117/36117 [00:24&lt;00:00, 1386.94 examples/s]"
          }
        },
        "694f85eb9d41453ea6a15663cc77d904": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10b0f660d8f84900bc9c17f84fa1a848",
            "placeholder": "​",
            "style": "IPY_MODEL_e411ce98cfc2494ea81e0f571d87a683",
            "value": "Map: 100%"
          }
        },
        "82fb3c74149549548fa0978404b28325": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_694f85eb9d41453ea6a15663cc77d904",
              "IPY_MODEL_f1f30762e0ee45c5ae0546c9f28ab80e",
              "IPY_MODEL_6930ad9c33554cb58eca93d56e18bafe"
            ],
            "layout": "IPY_MODEL_9bebe5cafdb24289bd757def59ef2d0f"
          }
        },
        "8e78d00a6096452b9359418790989408": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bebe5cafdb24289bd757def59ef2d0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e411ce98cfc2494ea81e0f571d87a683": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1f30762e0ee45c5ae0546c9f28ab80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4244d8904a824677b0a8e813691bd8a2",
            "max": 36117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e78d00a6096452b9359418790989408",
            "value": 36117
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
